#!/bin/bash

base_path=/ailab/user/wangwenhao/FedMobile/bash/output
model=qwen2-vl-7b-instruct
model_id_or_path=/ailab/user/wangwenhao/.cache/modelscope/hub/qwen/Qwen2-VL-7B-Instruct
#model=internvl2-8b
#model_id_or_path=/ailab/user/wangwenhao/.cache/modelscope/hub/OpenGVLab/InternVL2-8B
round=10
#val_dataset=/ailab/user/wangwenhao/ms-swift/c5_n100_val_apphete.jsonl
val_dataset=/ailab/user/wangwenhao/ms-swift/ablation/c10_n100_val_random_x0.jsonl
peft_list=(
#v250-20250214-133139
#v251-20250214-133250
#v252-20250214-133327
#v253-20250214-133356
#v254-20250214-133409
#v255-20250214-133538
#v256-20250214-133621
#v257-20250214-133639
#v258-20250214-134104
#v259-20250214-134136
#v260-20250214-134220
#v261-20250214-134301
#v262-20250214-134341
#v263-20250214-134425
#v264-20250214-134610
#v265-20250214-135506
#v266-20250214-135600
#v267-20250214-140143
#v268-20250214-140750
#v269-20250214-141104
#v270-20250214-141153
#v271-20250214-141232
#v272-20250214-141334
#v273-20250214-141432
#v274-20250214-141457
#v275-20250214-141730
#v276-20250214-141831
#v277-20250214-235920
#v278-20250215-000007
#v279-20250215-000117
#v280-20250215-000213
#v281-20250215-153535
#v282-20250215-153726
#v283-20250215-153809
#v284-20250215-153831
#v285-20250216-232440
#v286-20250216-232632
#v289-20250216-233206

#v295-20250220-012115
#v296-20250220-012702
#v297-20250220-014302
#v298-20250220-015245
#v299-20250220-093434
#v300-20250220-094013
#v301-20250220-100301
#v302-20250220-102445
#v303-20250220-103058
#v304-20250220-103058
#v305-20250220-104005
#v306-20250220-105208
#v307-20250220-105622
#v308-20250220-112409
#v309-20250220-113345
v314-20250223-141059


#  v2-20241224-222604
#  v3-20241224-222604
#  v7-20241219-0949
#  v12-20241224-184129
#  v13-20241224-184129
# high train
#v1-20241227-190359
#v2-20241228-003848
#v5-20241228-145342
#v6-20241228-145344
#v20-20241229-231622
#v40-20250103-004809
#v41-20250103-004929
#v42-20250103-010449
#v43-20250103-165523
#v44-20250103-170153
#v46-20250103-171405
#v50-20250103-171908
#v38-20250103-004324
#v57-20250104-121135
##v63-20250105-000326
#v64-20250105-000514
#v67-20250105-002942
#v69-20250105-003039
#v70-20250105-003104

# low train
#v7-20241228-151339
#v8-20241228-151339
#v9-20241228-151728
#v10-20241228-153239
#v11-20241228-153315
#v12-20241228-225340
#v13-20241229-115319
#v16-20241229-174822
#v17-20241229-225113
#v18-20241229-225113
#v22-20241230-181248
#v23-20241231-174820
#v24-20250101-143901
#
#v25-20241231-121508
#v26-20241231-121602
#v27-20241231-121711
#v28-20241231-121801
#v29-20241231-122425
#v30-20241231-123007

#v31-20241231-123200
#v32-20241231-170934
#v33-20241231-170934
#v34-20241231-171828
#v35-20241231-172004

#v36-20250103-001710
#v37-20250103-002846

#v39-20250103-004622

#v45-20250103-170409
#v47-20250103-171640
#v49-20250103-171817
#v51-20250103-172753
##v52-20250104-000700
##v53-20250104-000700
#v54-20250104-000700
#v55-20250104-000945
#v56-20250104-001043

#v58-20250104-153635
#v59-20250104-153800
#v60-20250104-163516
#v61-20250104-220425
#v62-20250104-225532
#v71-20250105-003553
#v72-20250105-003711

#v94-20250109-230155
#v102-20250110-152758
#v103-20250110-153647

#v107-20250111-173828
#v108-20250111-174639
#v109-20250111-175024
#v120-20250112-162008
#v121-20250112-164333
#v125-20250112-170150
#v20-20241229-231622
#v136-20250113-023206
#v137-20250113-023324
#v138-20250113-023604
#v140-20250113-135638
#v141-20250113-172146
#v148-20250114-142417
#v150-20250114-143104
#v151-20250114-150853
#v152-20250114-155100
#v153-20250114-192620
)

for i in ${peft_list[@]};
do
    echo $i
#    if [ ! -d "$base_path/$model/$i/global_lora_$round-merged" ]; then
#
#        echo "*** merge ***"
#        CUDA_VISIBLE_DEVICES=$1 swift merge_lora --ckpt_dir "$base_path/$model/$i/global_lora_$round" --merge_lora true --model_type $model
#
#    fi

    # inference
    # check already exsist
    jsonl_files=$(find "$base_path/$model/$i/global_lora_$round/infer_result" -type f -name "*.jsonl")

    if [ -z "$jsonl_files" ]; then
    MAX_PIXELS=602112 CUDA_VISIBLE_DEVICES=$1 swift infer --ckpt_dir "$base_path/$model/$i/global_lora_$round" \
      --val_dataset $val_dataset --model_type $model --model_id_or_path $model_id_or_path --sft_type lora
    fi

    # calculate acc
    jsonl_files=$(find "$base_path/$model/$i/global_lora_$round/infer_result" -type f -name "*.jsonl")
    for jsonl_file in $jsonl_files; do
    # Process each jsonl file here
    echo $jsonl_file
#    cd evaluation
    python test_swift.py --data_path "$jsonl_file"
    done


done
